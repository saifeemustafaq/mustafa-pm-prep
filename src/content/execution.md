# Execution Questions

## Metrics & Analysis
### Spotify has just launched a major podcast initiative. How would you measure its success? What would be your north star metric, and what supporting metrics would you track?
#### How to Answer

When answering this question, start by acknowledging the importance of measuring success for a major initiative like Spotify's podcast launch. Begin your response by briefly explaining why choosing the right metrics is crucial for evaluating the initiative's performance and guiding future decisions.

Next, introduce your chosen North Star metric, explaining why it's the most suitable indicator of success for this specific initiative. Be sure to highlight how this metric aligns with Spotify's overall business goals and reflects user value.

After introducing the North Star metric, discuss 3-4 supporting metrics that provide a more comprehensive view of the initiative's performance. For each metric, briefly explain its relevance and how it complements the North Star metric.

To structure your answer effectively, you might say something like: "To measure the success of Spotify's podcast initiative, I would focus on [North Star metric] as our primary indicator. This metric is crucial because [brief explanation]. To support this, I would also track [supporting metric 1], [supporting metric 2], and [supporting metric 3]."

#### Example Answer

To measure the success of Spotify's major podcast initiative, I would propose the following metrics:

North Star Metric: Weekly Active Podcast Listeners (WAPL)

This metric directly reflects user engagement with the new podcast feature and aligns with Spotify's goal of becoming a leading platform for audio content. It's a clear indicator of how well the podcast initiative is resonating with users and driving regular engagement.

Supporting metrics:

1. Podcast Listening Time: This metric measures the total time users spend listening to podcasts weekly. It complements WAPL by providing insight into the depth of engagement, not just the breadth.

2. Podcast-to-Music Ratio: This tracks the proportion of time users spend on podcasts versus music. It helps us understand if podcasts are cannibalizing music listening or if they're additive to overall platform usage.

3. Podcast Discovery Rate: This measures the percentage of users who listen to a new podcast each week. It indicates how well our recommendation algorithms and discovery features are working.

4. Podcast Retention Rate: This tracks the percentage of users who return to listen to subsequent episodes of a podcast series. It helps us understand the quality and stickiness of the podcast content we're offering.

By focusing on Weekly Active Podcast Listeners as our North Star metric, we can gauge the overall success of the initiative in terms of user adoption. The supporting metrics provide deeper insights into user behavior, content quality, and the impact on Spotify's core music business. Together, these metrics offer a comprehensive view of the podcast initiative's performance and can guide future strategy and product decisions.


### You're leading TikTok's growth team. What metrics would you use to evaluate the platform's success in new markets? How would you determine if the growth is sustainable?
#### How to Answer
Break down growth metrics into acquisition, engagement, and retention components.
#### Example Answer
Track Daily Active Users (DAU) growth rate, content creation ratio, and 30-day retention rates.

### Facebook is investing heavily in Groups. Design a measurement framework to evaluate whether this investment is paying off. What metrics would you prioritize and why?
#### How to Answer

To answer this question effectively, start by acknowledging the importance of Facebook's investment in Groups and the need for a comprehensive measurement framework. Begin with a high-level overview of your approach, then dive into the specific metrics you would prioritize.

Structure your answer around key areas of measurement, such as user engagement, growth, and business impact. For each area, explain the metrics you've chosen and why they're important for evaluating the success of Facebook Groups.

Here's a short starter example:

"To evaluate whether Facebook's investment in Groups is paying off, I would design a measurement framework that focuses on three key areas: user engagement, community growth, and business impact. Let's start with user engagement..."

Remember to tie your metrics back to Facebook's overall business goals and explain how they indicate success for the Groups initiative. Be prepared to discuss how you would collect and analyze this data, and how you might use the insights to inform future decisions about Groups.

#### Example Answer

To evaluate whether Facebook's investment in Groups is paying off, I would design a measurement framework focused on three key areas: user engagement, community growth, and business impact. Here's a breakdown of the metrics I would prioritize in each area and why:

##### User Engagement

**1. Daily Active Users (DAU) in Groups**
This metric shows how many users are actively engaging with Groups on a daily basis. A growing DAU indicates that Groups are becoming an integral part of users' daily Facebook experience.

**2. Time Spent in Groups**
Measuring the average time users spend in Groups per session and per day helps gauge the depth of engagement. An increase in time spent suggests that Groups are providing valuable content and interactions.

**3. Post Engagement Rate**
Calculate this by dividing the total number of interactions (likes, comments, shares) by the number of posts and the number of group members. This metric indicates how compelling and relevant the content within Groups is to members[6].

##### Community Growth

**4. Group Creation Rate**
Track the number of new Groups created over time. An upward trend suggests that users find value in creating and managing communities on the platform.

**5. Group Membership Growth**
Measure the rate at which users are joining new Groups. This metric helps assess the overall expansion of the Groups ecosystem[3].

**6. Group Retention Rate**
Calculate the percentage of members who remain active in a Group over a specific period. High retention rates indicate that Groups are providing long-term value to users[4].

##### Business Impact

**7. Ad Revenue from Groups**
If Facebook monetizes Groups through ads, track the revenue generated specifically from Group-related ad placements. This directly ties Groups to financial performance.

**8. User Acquisition Cost via Groups**
Measure how efficiently Groups are bringing new users to the Facebook platform by calculating the cost of acquiring new users through Group-related channels.

**9. Cross-Platform Engagement**
Track how Group activity influences engagement on other Facebook properties (e.g., main app, Messenger). This helps assess the broader impact of Groups on the Facebook ecosystem.

To collect and analyze this data, I would leverage Facebook's internal analytics tools and potentially develop new tracking mechanisms specific to Groups. I would establish benchmarks for each metric and monitor trends over time, looking for correlations between Group initiatives and metric improvements.

For example, if we see a significant increase in DAU and time spent in Groups following the launch of a new Group discovery feature, we could infer that the investment in that feature is paying off.

Additionally, I would segment the data by Group types, sizes, and user demographics to gain deeper insights. This could help identify which types of Groups are most successful and where to focus future investments.

Lastly, I would create a dashboard that visualizes these metrics and their trends, making it easy for stakeholders to quickly assess the performance of Groups. Regular reports would highlight key findings and recommendations for optimizing the Groups experience and maximizing return on investment.

By focusing on these metrics and continuously refining our measurement approach, we can effectively evaluate whether Facebook's investment in Groups is paying off and guide future strategic decisions in this area.


### How would you measure the success of a new feature aimed at increasing user engagement in a social media app?
#### How to Answer

To answer this question effectively, start by acknowledging the importance of measuring feature success in product development. Then, outline a structured approach to measuring the new feature's impact on user engagement.

Begin your response with something like: "To measure the success of a new feature aimed at increasing user engagement in a social media app, I would take a multi-faceted approach focusing on both quantitative and qualitative metrics."

Structure your answer around key areas such as:

1. Defining clear success criteria
2. Selecting relevant engagement metrics
3. Implementing proper tracking mechanisms
4. Analyzing user feedback
5. Comparing results against benchmarks

Use specific examples of metrics and methods throughout your explanation to demonstrate your knowledge. For instance, you might mention tracking daily active users (DAU) or measuring the feature adoption rate.

Remember to emphasize the importance of setting a baseline before launching the feature and continuously monitoring metrics over time to identify trends and patterns.

#### Example Answer

"To measure the success of a new feature aimed at increasing user engagement in a social media app, I would take a multi-faceted approach focusing on both quantitative and qualitative metrics.

First, I would establish clear success criteria aligned with our overall engagement goals. For example, let's say we've introduced a new 'Stories' feature similar to Instagram or Snapchat. Our primary goal might be to increase daily active users by 20% within three months of launch.

Next, I would select relevant engagement metrics to track. For our 'Stories' feature, key metrics would include:

1. Feature adoption rate: The percentage of users who have tried the Stories feature at least once.
2. Daily active users (DAU) of the feature: To track how many users are engaging with Stories daily.
3. Time spent in the app: To see if the new feature is increasing overall app usage.
4. Story completion rate: The percentage of users who view a Story from start to finish.
5. Story creation rate: How many users are creating their own Stories.

To implement proper tracking, I would work with our data team to set up event tracking for all interactions with the Stories feature. We would use our analytics tools to create a dashboard specifically for monitoring these metrics.

Qualitative feedback is equally important. I would implement in-app surveys for users who've interacted with the feature to gather their thoughts and suggestions. We would also closely monitor app store reviews and social media mentions for user sentiment about the new feature.

Before launch, we would establish a baseline for our current engagement metrics. Post-launch, we would compare our new metrics against this baseline weekly. I would also set up A/B tests to compare engagement levels between users who have access to the Stories feature and those who don't.

After three months, we would do a comprehensive analysis. If we've hit or exceeded our 20% DAU increase goal and see positive trends in other metrics like time spent in app and feature adoption rate, we would consider the feature a success. However, if we're falling short, we would dive deeper into the data and user feedback to identify areas for improvement.

Lastly, I would ensure we're not just looking at absolute numbers, but also comparing our metrics to industry benchmarks. For instance, if the average Story completion rate for social media apps is 70%, and we're achieving 80%, that's a strong indicator of success even if our DAU increase is slightly below target.

This comprehensive approach ensures we're getting a full picture of how the new feature is impacting user engagement, allowing us to make data-driven decisions about further development or iteration."



## Root Cause Analysis
### You're a PM at YouTube, and you notice that comment volumes have dropped by 40% across the platform in the last 24 hours. Walk me through how you would investigate this issue and what actions you would take.
#### How to Answer

To answer this question effectively, start by outlining a structured approach to investigating the issue. Begin with acknowledging the severity of the problem and the need for immediate action. Then, walk through your investigation process step-by-step, focusing on data analysis, cross-functional collaboration, and hypothesis testing.

Start your answer with something like: "This is a significant drop that requires immediate attention. I would approach this issue systematically, starting with data analysis to understand the scope and potential causes of the problem."

Structure your answer around these key areas:
1. Initial data analysis
2. Cross-functional collaboration
3. Hypothesis formation and testing
4. User impact assessment
5. Short-term mitigation strategies
6. Long-term solutions and monitoring

Use a conversational tone and provide specific examples of metrics you'd look at, teams you'd collaborate with, and potential hypotheses you'd explore. This demonstrates your practical knowledge and problem-solving skills.

#### Example Answer

"This is a significant drop that requires immediate attention. I would approach this issue systematically, starting with data analysis to understand the scope and potential causes of the problem.

First, I would dive into our analytics dashboard to confirm the 40% drop and gather more details. I would look at:
- The exact timing of the drop
- Whether it's affecting all types of videos or specific categories
- If it's impacting all user segments or specific demographics
- Any correlations with other metrics like views, likes, or shares

Next, I would reach out to our engineering team to check for any recent deployments or technical issues that might explain the drop. I would also consult with our content policy team to see if any recent policy changes could have affected commenting.

Based on this initial investigation, I would form some hypotheses. For example:
1. A bug in the comment system is preventing users from posting
2. A change in our recommendation algorithm is affecting video engagement
3. An external factor (like a major world event) is distracting users from engaging

To test these hypotheses, I would work with our data science team to run some quick analyses. For the bug hypothesis, we might look at error rates in our comment posting system. For the algorithm change, we would examine the correlation between recommendation changes and comment volumes.

Simultaneously, I would assess the user impact. Are we seeing an increase in support tickets or social media complaints about commenting issues? This would help prioritize our response.

For short-term mitigation, if we identify a bug, I would work with engineering to roll back recent changes or implement a hotfix. If it's an algorithm issue, we might consider temporarily reverting to a previous version while we investigate further.

Long-term, once we identify the root cause, we would develop a comprehensive solution. This might involve improving our testing processes, updating our content policies, or refining our recommendation algorithm. We would also implement additional monitoring to catch similar issues earlier in the future.

Throughout this process, I would keep stakeholders informed with regular updates and work on a communication plan for our users if necessary. The goal would be to not only solve this immediate issue but also to improve our systems to prevent similar problems in the future."



### As an Uber PM, you discover that driver cancellation rates have increased by 5% in the past month across all major markets. How would you analyze this problem and what potential solutions would you propose?
#### How to Answer

To answer this question effectively, start by outlining a structured approach to analyzing the problem and proposing solutions. Begin with a brief acknowledgment of the issue and its potential impact on Uber's business. Then, describe your analysis process, which should include data examination, stakeholder interviews, and root cause identification. Finally, propose potential solutions based on your findings.

Here's a concise way to structure your response:

1. Acknowledge the problem and its significance
2. Outline your analysis approach
3. Describe potential root causes
4. Propose data-driven solutions
5. Discuss implementation and measurement

Start your answer with something like: "To address the 5% increase in driver cancellation rates, I would first gather comprehensive data to understand the scope and nature of the problem. Then, I would analyze this data to identify potential root causes before proposing targeted solutions."

#### Example Answer

"Thank you for bringing this critical issue to my attention. A 5% increase in driver cancellation rates across major markets is significant and could negatively impact both rider experience and our bottom line. Here's how I would approach this problem:

First, I would gather and analyze relevant data to understand the scope and nature of the issue. This would include:

- Examining cancellation patterns by time of day, location, ride type, and driver demographics
- Comparing current cancellation rates with historical data
- Analyzing driver feedback and support tickets related to cancellations
- Reviewing any recent changes to the driver app, policies, or incentive structures

Next, I would conduct stakeholder interviews with our driver operations team, customer support, and a sample of drivers to gain qualitative insights.

Based on this analysis, let's say we identify three primary root causes:

1. Increased traffic congestion in certain areas, leading to longer pickup times
2. A recent change in the surge pricing algorithm that has reduced driver earnings
3. Growing competition from other ride-sharing platforms offering better incentives

Given these findings, I would propose the following solutions:

1. Implement a dynamic ETA system that accounts for real-time traffic conditions, providing drivers with more accurate pickup time estimates. This could reduce cancellations due to unexpected delays.

2. Revise the surge pricing algorithm to better balance driver earnings and ride demand. We could test this in a few markets to measure its impact on cancellation rates and overall driver satisfaction.

3. Introduce a tiered loyalty program for drivers, offering benefits such as higher commission rates or priority dispatch for drivers with low cancellation rates. This could incentivize drivers to complete more rides and stay loyal to Uber.

4. Enhance the driver app to provide more transparency on potential earnings for each ride before acceptance. This could help drivers make more informed decisions and reduce post-acceptance cancellations.

To implement these solutions, I would propose a phased rollout:

1. Start with the dynamic ETA system, as it addresses a key pain point without significant changes to our business model.
2. Simultaneously, begin testing the revised surge pricing algorithm in select markets.
3. Launch the driver loyalty program within a month, using insights from the first two initiatives to refine the offering.
4. Roll out the enhanced driver app features over the next quarter, incorporating feedback from drivers throughout the process.

To measure success, we would track:

- Overall driver cancellation rates
- Driver retention and satisfaction scores
- Rider satisfaction and rebooking rates
- Platform revenue and driver earnings

I would set a target to reduce the cancellation rate by 3% within the first three months of implementing these changes, with the goal of returning to pre-increase levels within six months. We would continuously monitor these metrics and adjust our approach as needed to ensure we're effectively addressing the issue."



### User retention for your mobile game has decreased by 15% over the last quarter. How would you approach identifying the cause and addressing the issue?
#### How to Answer

When addressing this question, start by emphasizing the importance of a data-driven approach. Begin your answer with a statement like, "To tackle this issue, I would first focus on gathering and analyzing relevant data to identify potential causes of the retention decrease."

Structure your response around a systematic approach:

1. Data collection and analysis
2. Hypothesis formation
3. User feedback
4. A/B testing
5. Implementation of solutions
6. Monitoring and iteration

Use a conversational tone to explain each step, providing brief examples or potential scenarios. For instance, when discussing data analysis, you might say, "I would look at metrics like daily active users, session length, and specific in-game events to spot any unusual patterns."

Remember to highlight the importance of cross-functional collaboration, mentioning how you'd work with different teams like engineering, design, and marketing to address the issue comprehensively.

#### Example Answer

"To address the 15% decrease in user retention over the last quarter, I would take a systematic, data-driven approach. 

First, I would dive deep into our analytics, focusing on key metrics such as daily and monthly active users, session length, level progression, and in-app purchase patterns. I would look for any significant changes or anomalies that coincide with the retention drop. For example, let's say I notice that the average session length has decreased from 25 minutes to 15 minutes, particularly for users who have been playing for 2-3 weeks.

Based on this data, I might hypothesize that players are losing interest around the mid-game stage. To validate this, I would collaborate with our user research team to conduct surveys and interviews with both current and churned users. We might discover that players find the difficulty curve too steep after the first few levels, leading to frustration and eventual churn.

Next, I would work with our game design and development teams to create potential solutions. We could design an A/B test where one group of users receives a modified difficulty curve with more gradual progression, while the control group keeps the current version. We would run this test for a few weeks, closely monitoring retention rates and user feedback.

Assuming the test group shows improved retention, we would implement the changes game-wide. However, the work doesn't stop there. I would establish a regular monitoring system to track the impact of these changes over time, setting up alerts for any significant fluctuations in our key retention metrics.

Throughout this process, I would ensure clear communication with all stakeholders, providing regular updates on our findings, actions, and results. This approach not only addresses the immediate retention issue but also sets up a framework for ongoing optimization of our user experience and retention strategies."
